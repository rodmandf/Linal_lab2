# Отчёт по лабораторной работе №2  
**Дисциплина:** Линейная алгебра и вычислительные модели  
**Тема:** Обучение однослойного перцептрона  

---

## 1. Цель работы
Реализовать обучение однослойного перцептрона для задачи бинарной классификации на сгенерированных данных, с отслеживанием точности и функции потерь на протяжении обучения.

---

## 2. Постановка задачи
Дана выборка из *m* объектов, каждый из которых описывается *n* признаками.  
Целевой признак \( y \in \{0, 1\} \).

**Цель:** построить модель, предсказывающую вероятность того, что \( y = 1 \), на основе признаков, и дополнительно отслеживать точность классификации на тренировочной выборке.

---

## 3. Математическая модель

### Активация и предсказание
\[
z = X \cdot w + b
\]

\[
\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}
\]

### Функция потерь и точность
Используется кросс-энтропийная функция потерь:
\[
J(w, b) = -\frac{1}{m} \sum_{i=1}^{m} \Big[ y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \Big]
\]

Точность классификации:
\[
Accuracy = \frac{1}{m} \sum_{i=1}^{m} [\hat{y}^{(i)} \ge 0.6 == y^{(i)}]
\]

### Обновление весов
\[
w := w - \alpha \cdot \frac{1}{m} X^T (\hat{y} - y)
\]

\[
b := b - \alpha \cdot \frac{1}{m} \sum (\hat{y} - y)
\]

---

## 4. Описание реализации
- **Генерация данных.** Случайные признаки и истинные веса, бинаризация меток по признаку \( z \ge 0 \).  
- **Модель.** Класс `Perceptron` реализует веса, сигмоидальную активацию, кросс-энтропийную функцию потерь, точность и градиентный спуск.  
- **Обучение.** Ведётся подсчёт истории функции потерь и точности по эпохам. Критерий классификации: \( \hat{y} \ge 0.6 \).  
- **Отображение.** После обучения строится график изменения функции потерь и точности по эпохам.

---

## 5. Результаты
Модель обучалась на выборке из **1000 объектов**, где **800 использовались для обучения**, а **200 — для тестирования**.  
Точность модели на обучающей выборке достигла высоких значений (**> 90%**) после **200 эпох**.  

График потерь показывает убывание, а график точности — рост, что говорит о корректной реализации.

---

## 6. Выводы
В данной работе был реализован и обучен однослойный перцептрон, отслеживающий как функцию потерь, так и точность классификации.  
Реализация проведена без использования специализированных библиотек.  
Полученные графики подтверждают сходимость алгоритма и успешность градиентного обучения.
